{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMKBTHA5Kn91pLz1hA9F1+/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5X0-KU-CfFoE","executionInfo":{"status":"ok","timestamp":1686839806703,"user_tz":-120,"elapsed":17965,"user":{"displayName":"Giorgia Gossi","userId":"12769328602676688820"}},"outputId":"5438979d-952c-4503-d892-558c828e5cd2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os\n","import spacy\n","from spacy.tokens import Doc\n","from spacy.tokens import DocBin"],"metadata":{"id":"hkg30mg_fNFi","executionInfo":{"status":"ok","timestamp":1686839852536,"user_tz":-120,"elapsed":10644,"user":{"displayName":"Giorgia Gossi","userId":"12769328602676688820"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["directory='/content/drive/MyDrive/DataSemantic_Project/3doc/'"],"metadata":{"id":"L2ZZ4cJNfVrN","executionInfo":{"status":"ok","timestamp":1686839861484,"user_tz":-120,"elapsed":260,"user":{"displayName":"Giorgia Gossi","userId":"12769328602676688820"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["trained_nlp = spacy.load(\"/content/drive/MyDrive/DataSemantic_Project/outpu2/model-best\")"],"metadata":{"id":"yZBtOWDjfcgk","executionInfo":{"status":"ok","timestamp":1686839878935,"user_tz":-120,"elapsed":5466,"user":{"displayName":"Giorgia Gossi","userId":"12769328602676688820"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["docbin=DocBin()\n","for filename in os.listdir(directory):\n","    with open(directory+filename) as f:\n","      a=''.join(f.readlines())\n","    a=a.replace('\\n', ' ').replace('\\t', ' ').lower()\n","    doc=trained_nlp(a)\n","    docbin.add(doc)\n","docbin.to_disk('/content/drive/MyDrive/DataSemantic_Project/provaBS.spacy')"],"metadata":{"id":"jQop5wDlfdXd","executionInfo":{"status":"ok","timestamp":1686840042007,"user_tz":-120,"elapsed":2526,"user":{"displayName":"Giorgia Gossi","userId":"12769328602676688820"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["directory1='/content/drive/MyDrive/DataSemantic_Project/pred_gold_doc/validation/'"],"metadata":{"id":"xBpjtxapx_0q","executionInfo":{"status":"ok","timestamp":1686844754552,"user_tz":-120,"elapsed":255,"user":{"displayName":"Giorgia Gossi","userId":"12769328602676688820"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["docbin_v=DocBin()\n","for filename in os.listdir(directory1):\n","    with open(directory1+filename) as f:\n","      a=''.join(f.readlines())\n","    a=a.replace('\\n', ' ').replace('\\t', ' ').lower()\n","    doc=trained_nlp(a)\n","    docbin_v.add(doc)\n","docbin_v.to_disk('/content/drive/MyDrive/DataSemantic_Project/provaBS_val.spacy')"],"metadata":{"id":"3iBUjB_vxc3J","executionInfo":{"status":"ok","timestamp":1686844757745,"user_tz":-120,"elapsed":1303,"user":{"displayName":"Giorgia Gossi","userId":"12769328602676688820"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["import srsly\n","import typer\n","import warnings\n","from pathlib import Path\n","\n","import spacy\n","from spacy.tokens import DocBin"],"metadata":{"id":"z-sOKqAogLCU","executionInfo":{"status":"ok","timestamp":1686840083855,"user_tz":-120,"elapsed":225,"user":{"displayName":"Giorgia Gossi","userId":"12769328602676688820"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["!python -m spacy init fill-config /content/drive/MyDrive/DataSemantic_Project/base_configBS.cfg /content/drive/MyDrive/DataSemantic_Project/configBS.cfg"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x2P7AKO9gQvc","executionInfo":{"status":"ok","timestamp":1686840217303,"user_tz":-120,"elapsed":11039,"user":{"displayName":"Giorgia Gossi","userId":"12769328602676688820"}},"outputId":"420151f2-2a7b-4308-b025-a3e0b1f67a21"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-06-15 14:43:31.088164: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n","\u001b[38;5;2m✔ Saved config\u001b[0m\n","/content/drive/MyDrive/DataSemantic_Project/configBS.cfg\n","You can now add your data and train your pipeline:\n","python -m spacy train configBS.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"]}]},{"cell_type":"code","source":["!python -m spacy train /content/drive/MyDrive/DataSemantic_Project/configBS.cfg --output /content/drive/MyDrive/DataSemantic_Project/output3_testBS"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IfzOtVM0gxRc","executionInfo":{"status":"ok","timestamp":1686841873750,"user_tz":-120,"elapsed":1632199,"user":{"displayName":"Giorgia Gossi","userId":"12769328602676688820"}},"outputId":"9f94aaf9-27ee-450f-d989-f91c30b993f6"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-06-15 14:44:06.393689: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[38;5;4mℹ Saving to output directory:\n","/content/drive/MyDrive/DataSemantic_Project/output3_testBS\u001b[0m\n","\u001b[38;5;4mℹ Using CPU\u001b[0m\n","\u001b[1m\n","=========================== Initializing pipeline ===========================\u001b[0m\n","[2023-06-15 14:44:09,341] [INFO] Set up nlp object from config\n","[2023-06-15 14:44:09,364] [INFO] Pipeline: ['tok2vec', 'ner']\n","[2023-06-15 14:44:09,369] [INFO] Created vocabulary\n","[2023-06-15 14:44:09,371] [INFO] Finished initializing nlp object\n","[2023-06-15 14:44:14,984] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n","\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n","\u001b[1m\n","============================= Training pipeline =============================\u001b[0m\n","\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n","\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n","E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n","---  ------  ------------  --------  ------  ------  ------  ------\n","  0       0          0.00   2227.71    0.00    0.00    0.00    0.00\n"," 66     200       7036.04  65337.18  100.00  100.00  100.00    1.00\n","133     400          0.27      0.27  100.00  100.00  100.00    1.00\n","200     600          0.00      0.00  100.00  100.00  100.00    1.00\n","266     800          0.00      0.00  100.00  100.00  100.00    1.00\n","333    1000          8.09      4.27  100.00  100.00  100.00    1.00\n","400    1200         74.63     41.92  100.00  100.00  100.00    1.00\n","466    1400         64.15     17.77  100.00  100.00  100.00    1.00\n","533    1600          9.77      3.78  100.00  100.00  100.00    1.00\n","600    1800          0.00      0.00  100.00  100.00  100.00    1.00\n","\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n","/content/drive/MyDrive/DataSemantic_Project/output3_testBS/model-last\n"]}]},{"cell_type":"code","source":["import typer\n","from pathlib import Path\n","\n","import spacy"],"metadata":{"id":"JVBUcAvcq53_","executionInfo":{"status":"ok","timestamp":1686842879094,"user_tz":-120,"elapsed":258,"user":{"displayName":"Giorgia Gossi","userId":"12769328602676688820"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def create_config(model_name: str, component_to_update: str, output_path: Path):\n","    nlp = spacy.load(model_name)\n","\n","    # create a new config as a copy of the loaded pipeline's config\n","    config = nlp.config.copy()\n","\n","    # revert most training settings to the current defaults\n","    default_config = spacy.blank(nlp.lang).config\n","    config[\"corpora\"] = default_config[\"corpora\"]\n","    config[\"training\"][\"logger\"] = default_config[\"training\"][\"logger\"]\n","\n","    # copy tokenizer and vocab settings from the base model, which includes\n","    # lookups (lexeme_norm) and vectors, so they don't need to be copied or\n","    # initialized separately\n","    config[\"initialize\"][\"before_init\"] = {\n","        \"@callbacks\": \"spacy.copy_from_base_model.v1\",\n","        \"tokenizer\": model_name,\n","        \"vocab\": model_name,\n","    }\n","    config[\"initialize\"][\"lookups\"] = None\n","    config[\"initialize\"][\"vectors\"] = None\n","\n","    # source all components from the loaded pipeline and freeze all except the\n","    # component to update; replace the listener for the component that is\n","    # being updated so that it can be updated independently\n","    config[\"training\"][\"frozen_components\"] = []\n","    for pipe_name in nlp.component_names:\n","        if pipe_name != component_to_update:\n","            config[\"components\"][pipe_name] = {\"source\": model_name}\n","            config[\"training\"][\"frozen_components\"].append(pipe_name)\n","        else:\n","            config[\"components\"][pipe_name] = {\n","                \"source\": model_name,\n","                \"replace_listeners\": [\"model.tok2vec\"],\n","            }\n","\n","    # save the config\n","    config.to_disk(output_path)\n","\n","\n","#if __name__ == \"__main__\":\n"," #   typer.run(create_config)"],"metadata":{"id":"lde0CsNNq7NH","executionInfo":{"status":"ok","timestamp":1686843150507,"user_tz":-120,"elapsed":295,"user":{"displayName":"Giorgia Gossi","userId":"12769328602676688820"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["create_config(\"/content/drive/MyDrive/DataSemantic_Project/outpu2/model-best\", 'ner', '/content/drive/MyDrive/DataSemantic_Project/prova_config.cfg')"],"metadata":{"id":"1MhAALfPr92N","executionInfo":{"status":"ok","timestamp":1686843373451,"user_tz":-120,"elapsed":1655,"user":{"displayName":"Giorgia Gossi","userId":"12769328602676688820"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["!python -m spacy train /content/drive/MyDrive/DataSemantic_Project/prova_config.cfg --output /content/drive/MyDrive/DataSemantic_Project/output3_testBS"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QA7jkSRttVEB","executionInfo":{"status":"ok","timestamp":1686846364324,"user_tz":-120,"elapsed":1495440,"user":{"displayName":"Giorgia Gossi","userId":"12769328602676688820"}},"outputId":"9ca4f5c6-dac1-4f07-dd9a-4dbf74a484af"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-06-15 16:01:14.601639: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","\u001b[38;5;4mℹ Saving to output directory:\n","/content/drive/MyDrive/DataSemantic_Project/output3_testBS\u001b[0m\n","\u001b[38;5;4mℹ Using CPU\u001b[0m\n","\u001b[1m\n","=========================== Initializing pipeline ===========================\u001b[0m\n","[2023-06-15 16:01:18,185] [INFO] Set up nlp object from config\n","[2023-06-15 16:01:18,208] [INFO] Pipeline: ['tok2vec', 'ner']\n","[2023-06-15 16:01:18,209] [INFO] Resuming training for: ['ner']\n","[2023-06-15 16:01:18,222] [INFO] Copying tokenizer from: /content/drive/MyDrive/DataSemantic_Project/outpu2/model-best\n","[2023-06-15 16:01:19,020] [INFO] Copying vocab from: /content/drive/MyDrive/DataSemantic_Project/outpu2/model-best\n","[2023-06-15 16:01:19,056] [INFO] Created vocabulary\n","[2023-06-15 16:01:19,058] [INFO] Finished initializing nlp object\n","[2023-06-15 16:01:19,058] [INFO] Initialized pipeline components: []\n","\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n","\u001b[1m\n","============================= Training pipeline =============================\u001b[0m\n","\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n","\u001b[38;5;4mℹ Frozen components: ['tok2vec']\u001b[0m\n","\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n","E    #       LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n","---  ------  --------  ------  ------  ------  ------\n","  0       0      7.95   94.90  100.00   90.29    0.95\n"," 66     200     55.95   90.72   96.70   85.44    0.91\n","133     400      0.44   89.47   97.70   82.52    0.89\n","200     600      0.00   89.47   97.70   82.52    0.89\n","266     800      0.00   89.47   97.70   82.52    0.89\n","333    1000     94.60   87.31   91.49   83.50    0.87\n","400    1200     40.71   88.42   96.55   81.55    0.88\n","466    1400      0.00   88.42   96.55   81.55    0.88\n","533    1600      0.00   89.36   98.82   81.55    0.89\n","\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n","/content/drive/MyDrive/DataSemantic_Project/output3_testBS/model-last\n"]}]}]}